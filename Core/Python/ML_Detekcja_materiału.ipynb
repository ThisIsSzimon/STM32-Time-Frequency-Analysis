{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f891dca7",
   "metadata": {},
   "source": [
    "# Użycie wcześniej wytrenowanego modelu do nowych danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23965e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KOMÓRKA 0 – funkcje pomocnicze (takie same jak w notebooku treningowym)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "LSB_TO_G = 0.0039  # FULL_RES=1\n",
    "\n",
    "def load_xyz_from_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "    cols_lower = {c.lower(): c for c in df.columns}\n",
    "\n",
    "    # czas\n",
    "    time_col = None\n",
    "    for key, orig in cols_lower.items():\n",
    "        if \"time\" in key or \"czas\" in key:\n",
    "            time_col = orig\n",
    "            break\n",
    "\n",
    "    x_col = y_col = z_col = None\n",
    "    for key, orig in cols_lower.items():\n",
    "        if x_col is None and key.startswith(\"x\"):\n",
    "            x_col = orig\n",
    "        if y_col is None and key.startswith(\"y\"):\n",
    "            y_col = orig\n",
    "        if z_col is None and key.startswith(\"z\"):\n",
    "            z_col = orig\n",
    "\n",
    "    if time_col is None or x_col is None or y_col is None or z_col is None:\n",
    "        raise ValueError(\n",
    "            f\"Nie mogę znaleźć kolumn w {path}, mam: {df.columns.tolist()}\"\n",
    "        )\n",
    "\n",
    "    t  = df[time_col].to_numpy()\n",
    "    ax = df[x_col].to_numpy() * LSB_TO_G\n",
    "    ay = df[y_col].to_numpy() * LSB_TO_G\n",
    "    az = df[z_col].to_numpy() * LSB_TO_G\n",
    "\n",
    "    dt = np.mean(np.diff(t))\n",
    "    Fs = 1.0 / dt\n",
    "    return t, ax, ay, az, Fs\n",
    "\n",
    "\n",
    "# parametry detekcji (możesz skopiować dokładnie z poprzedniego nb)\n",
    "BASELINE_LEN_S   = 0.5\n",
    "SMOOTH_LEN_S     = 0.05\n",
    "STD_THRESHOLD    = 3.0\n",
    "DELAY_AFTER_JUMP = 1.0\n",
    "WINDOW_LEN_S     = 12.0\n",
    "\n",
    "def detect_steady_window(t, ax, ay, az,\n",
    "                         baseline_len_s=BASELINE_LEN_S,\n",
    "                         smooth_len_s=SMOOTH_LEN_S,\n",
    "                         std_threshold=STD_THRESHOLD,\n",
    "                         delay_after_jump=DELAY_AFTER_JUMP,\n",
    "                         window_len_s=WINDOW_LEN_S):\n",
    "    mag = np.sqrt(ax**2 + ay**2 + az**2)\n",
    "\n",
    "    t0 = t[0]\n",
    "    baseline_mask = t <= (t0 + baseline_len_s)\n",
    "    baseline = mag[baseline_mask]\n",
    "    mu = baseline.mean()\n",
    "    sigma = baseline.std()\n",
    "    thresh = mu + std_threshold * sigma\n",
    "\n",
    "    dt = np.mean(np.diff(t))\n",
    "    Fs = 1.0 / dt\n",
    "    win_samples = int(round(smooth_len_s * Fs))\n",
    "    if win_samples < 1:\n",
    "        win_samples = 1\n",
    "    kernel = np.ones(win_samples) / win_samples\n",
    "    mag_smooth = np.convolve(mag, kernel, mode=\"same\")\n",
    "\n",
    "    idx_candidates = np.where(mag_smooth > thresh)[0]\n",
    "    if len(idx_candidates) == 0:\n",
    "        t_start = t0 + 1.0\n",
    "    else:\n",
    "        idx_event = idx_candidates[0]\n",
    "        t_event   = t[idx_event]\n",
    "        t_start   = t_event + delay_after_jump\n",
    "\n",
    "    t_end = t_start + window_len_s\n",
    "    if t_end > t[-1]:\n",
    "        t_end = t[-1]\n",
    "        t_start = t_end - window_len_s\n",
    "        if t_start < t0:\n",
    "            t_start = t0\n",
    "\n",
    "    mask_seg = (t >= t_start) & (t <= t_end)\n",
    "\n",
    "    return (t[mask_seg],\n",
    "            ax[mask_seg],\n",
    "            ay[mask_seg],\n",
    "            az[mask_seg],\n",
    "            (t_start, t_end),\n",
    "            mag,\n",
    "            mag_smooth,\n",
    "            thresh)\n",
    "\n",
    "\n",
    "# CWT osi Y\n",
    "import pywt\n",
    "\n",
    "def compute_cwt_freq_y(y, Fs, fmin=0.5, fmax=400, n_freqs=256,\n",
    "                       wavelet=\"cmor3.5-1.0\", normalize=True):\n",
    "    y = y - y.mean()\n",
    "    if normalize:\n",
    "        rms = np.sqrt((y**2).mean())\n",
    "        if rms > 0:\n",
    "            y = y / rms\n",
    "\n",
    "    dt = 1.0 / Fs\n",
    "    freqs = np.linspace(fmin, fmax, n_freqs)\n",
    "    scales = pywt.frequency2scale(wavelet, freqs * dt)\n",
    "\n",
    "    coeffs, _ = pywt.cwt(y, scales, wavelet, sampling_period=dt)\n",
    "    power = np.abs(coeffs)\n",
    "    power_db = 20 * np.log10(power + 1e-12)\n",
    "    return freqs, power_db\n",
    "\n",
    "\n",
    "# >>> TO JEST KLUCZOWA FUNKCJA – cechy MUSZĄ mieć te same nazwy jak przy trenowaniu <<<\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "def extract_features_from_cwt(freqs, power_db, bands):\n",
    "    \"\"\"\n",
    "    Zwraca słownik z cechami:\n",
    "      E_*, Var_*, Kurt_*, centroid_hz, mean_db, std_db, spec_flatness, rolloff_hz\n",
    "    Dokładnie takie nazwy są zapisane w meta[\"feature_cols\"].\n",
    "    \"\"\"\n",
    "    feats = {}\n",
    "\n",
    "    # uśrednione widmo (po czasie)\n",
    "    mean_spec = power_db.mean(axis=1)       # (n_freq,)\n",
    "    lin_spec  = 10 ** (mean_spec / 20.0)    # ~amplituda\n",
    "\n",
    "    # cechy pasmowe\n",
    "    for (f1, f2) in bands:\n",
    "        label = f\"{f1:.0f}_{f2:.0f}\"\n",
    "        mask = (freqs >= f1) & (freqs <= f2)\n",
    "\n",
    "        if not np.any(mask):\n",
    "            feats[f\"E_{label}\"]    = np.nan\n",
    "            feats[f\"Var_{label}\"]  = np.nan\n",
    "            feats[f\"Kurt_{label}\"] = np.nan\n",
    "            continue\n",
    "\n",
    "        band_vals = power_db[mask, :].ravel()   # dB w paśmie\n",
    "\n",
    "        feats[f\"E_{label}\"]   = band_vals.mean()\n",
    "        feats[f\"Var_{label}\"] = band_vals.var()\n",
    "\n",
    "        if band_vals.size > 1:\n",
    "            feats[f\"Kurt_{label}\"] = kurtosis(band_vals, fisher=False, bias=False)\n",
    "        else:\n",
    "            feats[f\"Kurt_{label}\"] = np.nan\n",
    "\n",
    "    # centroid częstotliwościowy\n",
    "    w_sum = lin_spec.sum()\n",
    "    if w_sum > 0:\n",
    "        feats[\"centroid_hz\"] = (freqs * lin_spec).sum() / w_sum\n",
    "    else:\n",
    "        feats[\"centroid_hz\"] = np.nan\n",
    "\n",
    "    # globalne statystyki widma\n",
    "    feats[\"mean_db\"] = mean_spec.mean()\n",
    "    feats[\"std_db\"]  = mean_spec.std()\n",
    "\n",
    "    # spectral flatness\n",
    "    pos = lin_spec > 0\n",
    "    if np.any(pos):\n",
    "        gmean = np.exp(np.log(lin_spec[pos]).mean())\n",
    "        amean = lin_spec[pos].mean()\n",
    "        feats[\"spec_flatness\"] = gmean / (amean + 1e-12)\n",
    "    else:\n",
    "        feats[\"spec_flatness\"] = np.nan\n",
    "\n",
    "    # spectral rolloff (np. 95% energii)\n",
    "    psd = lin_spec ** 2\n",
    "    cumsum = np.cumsum(psd)\n",
    "    if cumsum[-1] > 0:\n",
    "        thresh = 0.95 * cumsum[-1]\n",
    "        idx = np.searchsorted(cumsum, thresh)\n",
    "        idx = min(idx, len(freqs) - 1)\n",
    "        feats[\"rolloff_hz\"] = freqs[idx]\n",
    "    else:\n",
    "        feats[\"rolloff_hz\"] = np.nan\n",
    "\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c18b1195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wczytano model z: models\\propeller_rf_cwt.joblib\n",
      "Cechy używane przez model: ['E_200_400', 'Var_200_400', 'Var_40_100', 'E_0_40', 'E_40_100', 'centroid_hz', 'E_100_200', 'mean_db', 'spec_flatness', 'rolloff_hz']\n",
      "Pasma: [(0.5, 40), (40, 100), (100, 200), (200, 400)]\n"
     ]
    }
   ],
   "source": [
    "from joblib import load\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL_DIR = Path(\"models\")\n",
    "\n",
    "model_path = MODEL_DIR / \"propeller_rf_cwt.joblib\"\n",
    "meta_path  = MODEL_DIR / \"propeller_rf_cwt_meta.json\"\n",
    "\n",
    "clf = load(model_path)\n",
    "print(\"Wczytano model z:\", model_path)\n",
    "\n",
    "with open(meta_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "feature_cols = meta[\"feature_cols\"]\n",
    "bands = [tuple(b) for b in meta[\"bands\"]]   # JSON da listy, robimy tuplę\n",
    "\n",
    "print(\"Cechy używane przez model:\", feature_cols)\n",
    "print(\"Pasma:\", bands)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6edb0487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def predict_material_for_files(csv_paths):\n",
    "    \"\"\"\n",
    "    Dla listy plików CSV:\n",
    "      - wycina ustaloną pracę (detect_steady_window),\n",
    "      - dzieli na 2 połówki,\n",
    "      - liczy CWT + cechy (extract_features_from_cwt),\n",
    "      - używa zapisanego modelu clf do predykcji.\n",
    "    Zwraca: DataFrame z predykcjami dla każdej połówki\n",
    "            oraz podsumowanie majority vote na plik.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for path in csv_paths:\n",
    "        path = Path(path)\n",
    "        print(f\"Przetwarzam: {path}\")\n",
    "\n",
    "        # 1) wczytanie + ustalona praca\n",
    "        t, ax, ay, az, Fs = load_xyz_from_csv(path)\n",
    "        t_seg, ax_seg, ay_seg, az_seg, (t_start, t_end), mag, mag_smooth, thresh = \\\n",
    "            detect_steady_window(t, ax, ay, az)\n",
    "\n",
    "        # 2) podział na dwie połówki jak przy treningu\n",
    "        N   = len(ay_seg)\n",
    "        mid = N // 2\n",
    "        halves = [\n",
    "            (t_seg[:mid],  ay_seg[:mid]),\n",
    "            (t_seg[mid:], ay_seg[mid:]),\n",
    "        ]\n",
    "\n",
    "        for part_idx, (t_part, y_part) in enumerate(halves):\n",
    "            # 3) CWT osi Y\n",
    "            freqs, power_db = compute_cwt_freq_y(\n",
    "                y_part, Fs,\n",
    "                fmin=0.5,\n",
    "                fmax=400,\n",
    "                n_freqs=256\n",
    "            )\n",
    "\n",
    "            # 4) cechy\n",
    "            feat_dict = extract_features_from_cwt(freqs, power_db, bands)\n",
    "\n",
    "            row_feat = {\n",
    "                \"file_path\": str(path),\n",
    "                \"part\": part_idx,\n",
    "            }\n",
    "            row_feat.update(feat_dict)\n",
    "            rows.append(row_feat)\n",
    "\n",
    "    df_parts = pd.DataFrame(rows)\n",
    "\n",
    "    # 5) macierz cech w tej samej kolejności jak przy treningu\n",
    "    X_new = df_parts[feature_cols].values\n",
    "\n",
    "    # 6) predykcja + prawdopodobieństwa\n",
    "    y_pred = clf.predict(X_new)\n",
    "    proba  = clf.predict_proba(X_new)\n",
    "\n",
    "    df_parts[\"pred_material\"] = y_pred\n",
    "    df_parts[\"proba_fabryczne\"] = proba[:, list(clf.classes_).index(\"fabryczne\")]\n",
    "    df_parts[\"proba_kupione\"]   = proba[:, list(clf.classes_).index(\"kupione\")]\n",
    "\n",
    "    # 7) majority vote na poziomie pliku\n",
    "    summary = (\n",
    "        df_parts.groupby(\"file_path\")[\"pred_material\"]\n",
    "                .agg(lambda s: s.value_counts().idxmax())\n",
    "                .reset_index(name=\"pred_material_majority\")\n",
    "    )\n",
    "\n",
    "    return df_parts, summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c91d90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przetwarzam: data\\daneTestowe\\rpm_i_adxL_test.csv\n",
      "Predykcje dla poówek:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "file_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "part",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pred_material",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "proba_fabryczne",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "proba_kupione",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "91715694-70f3-438b-9eed-1e8eae2ba6d3",
       "rows": [
        [
         "0",
         "data\\daneTestowe\\rpm_i_adxL_test.csv",
         "0",
         "kupione",
         "0.3125",
         "0.6875"
        ],
        [
         "1",
         "data\\daneTestowe\\rpm_i_adxL_test.csv",
         "1",
         "kupione",
         "0.3225",
         "0.6775"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>part</th>\n",
       "      <th>pred_material</th>\n",
       "      <th>proba_fabryczne</th>\n",
       "      <th>proba_kupione</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data\\daneTestowe\\rpm_i_adxL_test.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>kupione</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data\\daneTestowe\\rpm_i_adxL_test.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>kupione</td>\n",
       "      <td>0.3225</td>\n",
       "      <td>0.6775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              file_path  part pred_material  proba_fabryczne  \\\n",
       "0  data\\daneTestowe\\rpm_i_adxL_test.csv     0       kupione           0.3125   \n",
       "1  data\\daneTestowe\\rpm_i_adxL_test.csv     1       kupione           0.3225   \n",
       "\n",
       "   proba_kupione  \n",
       "0         0.6875  \n",
       "1         0.6775  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "new_paths = [Path(\"data/daneTestowe/rpm_i_adxL_test.csv\")]\n",
    "\n",
    "df_parts, df_summary = predict_material_for_files(new_paths)\n",
    "\n",
    "print(\"Predykcje dla poówek:\")\n",
    "display(df_parts[[\"file_path\", \"part\", \"pred_material\",\n",
    "                  \"proba_fabryczne\", \"proba_kupione\"]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
